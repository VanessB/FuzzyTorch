{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blind-anderson",
   "metadata": {},
   "source": [
    "# Нечеткие автоматы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzy_torch import logic\n",
    "from fuzzy_torch.modules import ffsa, indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "font = {'family' : 'Liberation Sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 30}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-european",
   "metadata": {},
   "source": [
    "## Проверка переходов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logic = logic.Hamacher\n",
    "fuzzy_fsa = ffsa.TimeIndependentFFSA(Logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление состояний и переходов.\n",
    "fuzzy_fsa.states = [0, 1]\n",
    "fuzzy_fsa.transitions.append(ffsa.FuzzyTransition(0, 1, indicators.Sigmoid(1, 1.0, 0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Начальные активации.\n",
    "activation = torch.tensor(np.array([[1.0, 0.0],\n",
    "                                    [1.0, 0.0],\n",
    "                                    [1.0, 0.0],\n",
    "                                    [1.0, 0.0]]).astype(np.float32), requires_grad=True)\n",
    "\n",
    "# Последовательности.\n",
    "sequence = torch.tensor(np.array([[-1.0, -1.0, 0.0, 1.0, 1.0],\n",
    "                                  [-10.0, -5.0, -1.0, 0.0, 10.0],\n",
    "                                  [-10.0, -10.0, -10.0, -10.0, 0.0],\n",
    "                                  [-0.5, -0.5, -0.5, -0.5, -0.5]]).astype(np.float32), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "Activations = [activation]\n",
    "for step in range(sequence.size()[1]):\n",
    "    Activations.append(fuzzy_fsa(sequence[:, step][:,None], Activations[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(Activations[-1][:,1]).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fuzzy_fsa.transitions[0].condition.linear.weight.grad)\n",
    "print(fuzzy_fsa.transitions[0].condition.linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-slope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "tamil-ministry",
   "metadata": {},
   "source": [
    "## Последовательность с переключением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchingRegressor(torch.nn.Module):\n",
    "    def __init__(self, logic, ffsa):\n",
    "        super().__init__()\n",
    "        self.logic = logic\n",
    "        self.ffsa = ffsa\n",
    "        self.debug = False\n",
    "        \n",
    "    def forward(self, input, init_activation):\n",
    "        steps = input.size()[1]\n",
    "        \n",
    "        activations = [init_activation]\n",
    "        outputs = []\n",
    "        for step in range(steps):\n",
    "            # Срез входа по текущему шагу.\n",
    "            input_on_current_step = input[:, step]\n",
    "            \n",
    "            # Новые активации (согласно нечеткому конечному автомату).\n",
    "            activations.append(self.ffsa(input_on_current_step, activations[-1]))\n",
    "            \n",
    "            # Получение выходов регрессоров.\n",
    "            output = [state(input_on_current_step) for state in self.ffsa.states]\n",
    "            output = torch.stack(output, dim=1)\n",
    "            outputs.append(torch.einsum(\"bo,bo...->b...\", activations[-1], output))\n",
    "            \n",
    "        return torch.stack(outputs, dim=1), torch.stack(activations, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Логика.\n",
    "#Logic = logic.Godel\n",
    "#Logic = logic.Product\n",
    "#Logic = logic.Lukasiewicz\n",
    "#Logic = logic.Nilpotent\n",
    "Logic = logic.Hamacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = SwitchingRegressor(Logic, ffsa.TimeIndependentFFSA(Logic, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.ffsa.states = torch.nn.ModuleList([torch.nn.Linear(2, 1), torch.nn.Linear(2, 1), torch.nn.Linear(2, 1)])\n",
    "regressor.ffsa.transitions = torch.nn.ModuleList([ffsa.FuzzyTransition(0, 1, indicators.Sigmoid(2)),\n",
    "                                                  ffsa.FuzzyTransition(0, 2, indicators.Sigmoid(2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-conspiracy",
   "metadata": {},
   "source": [
    "### Набор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "class SwitchingSequences(torch.utils.data.Dataset):\n",
    "    def __init__(self, length=100, delta=3):       \n",
    "        self.length = length\n",
    "        self.delta = delta\n",
    "        self.noize = stats.norm()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 16384\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        switch_index_start = np.random.choice(np.arange(0, self.length - self.delta - 1), 1)[0]\n",
    "        switch_index_end = np.random.choice(np.arange(switch_index_start + self.delta, self.length), 1)[0]\n",
    "        switch_type = np.random.choice([-1.0, 1.0], 1)[0]\n",
    "        \n",
    "        X = np.ones((self.length, 2))\n",
    "        X[:,1] *= switch_type\n",
    "        X[:switch_index_start, 1] = 0.0\n",
    "        X[switch_index_end:, 1] = 0.0\n",
    "        X += self.noize.rvs(X.shape) * 0.1\n",
    "        \n",
    "        y = np.ones((self.length))\n",
    "        y[switch_index_start:] = 2.0 * switch_type * X[switch_index_start:, 0]\n",
    "        y += self.noize.rvs(y.shape) * 0.1\n",
    "        \n",
    "        return X.astype(np.float32), y.astype(np.float32)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SwitchingSequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(regressor.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-cooking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        x, true_y = data\n",
    "        init_activations = torch.zeros(x.size()[0], 3)\n",
    "        init_activations[:,0] = 1.0\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        y, activations = regressor(x, init_activations)\n",
    "        eval_loss = loss(y, true_y)\n",
    "        eval_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += eval_loss.item()\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = dataset[0]\n",
    "X = torch.tensor(X)[None,:]\n",
    "y, activations = regressor(X, torch.tensor(np.array([[1.0, 0.0, 0.0]]).astype(np.float32)))\n",
    "\n",
    "print(y_true.squeeze())\n",
    "print(y.squeeze().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations.argmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations.sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Первое условие (параметры):\")\n",
    "print(regressor.ffsa.transitions[0].condition.linear.weight.detach().numpy())\n",
    "print(regressor.ffsa.transitions[0].condition.linear.bias.detach().numpy())\n",
    "\n",
    "print(\"Второе условие (параметры):\")\n",
    "print(regressor.ffsa.transitions[1].condition.linear.weight.detach().numpy())\n",
    "print(regressor.ffsa.transitions[1].condition.linear.bias.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "\n",
    "fig.set_figheight(12)\n",
    "fig.set_figwidth(24)\n",
    "ax.grid(color='#000000', alpha=0.15, linestyle='-', linewidth=1, which='major')\n",
    "ax.grid(color='#000000', alpha=0.1, linestyle='-', linewidth=0.5, which='minor')\n",
    "\n",
    "ax.set_xlabel('Время')\n",
    "ax.set_ylabel('Значение')\n",
    "\n",
    "T = np.arange(dataset.length)\n",
    "ax.plot(T, X[0,:], label=\"X(t)\")\n",
    "ax.plot(T, y_true, label=\"y(t)\")\n",
    "#ax.plot(T, y[0].detach().numpy(), label=\"y'(t)\")\n",
    "\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-organization",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
