{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нечеткие автоматы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzy_torch import logic\n",
    "from fuzzy_torch.modules import ffsa, indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка переходов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logic = logic.Hamacher\n",
    "fuzzy_fsa = ffsa.TimeDependentFFSA(Logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление состояний и переходов.\n",
    "fuzzy_fsa.states = [0, 1]\n",
    "fuzzy_fsa.transitions.append(ffsa.FuzzyTransitionContinuous(0, 1, indicators.Sigmoid(1, 1.0, 0.0), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Начальные активации.\n",
    "activation = torch.tensor(np.array([[1.0, 0.0],\n",
    "                                    [1.0, 0.0],\n",
    "                                    [1.0, 0.0],\n",
    "                                    [1.0, 0.0]]).astype(np.float32), requires_grad=True)\n",
    "\n",
    "# Последовательности.\n",
    "sequence = torch.tensor(np.array([[-1.0, -1.0, 0.0, 1.0, 1.0],\n",
    "                                  [-10.0, -5.0, -1.0, 0.0, 10.0],\n",
    "                                  [-10.0, -10.0, -10.0, -10.0, 0.0],\n",
    "                                  [-0.5, -0.5, -0.5, -0.5, -0.5]]).astype(np.float32), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Activations = [activation]\n",
    "for step in range(sequence.size()[1]):\n",
    "    Activations.append(fuzzy_fsa(sequence[:, step][:,None], Activations[-1], 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(Activations[-1][:,1]).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.]], requires_grad=True), tensor([[9.7311e-01, 2.6894e-02],\n",
       "         [1.0000e+00, 4.5398e-06],\n",
       "         [1.0000e+00, 4.5398e-06],\n",
       "         [9.6225e-01, 3.7754e-02]], grad_fn=<ClampBackward1>), tensor([[9.4641e-01, 5.3590e-02],\n",
       "         [9.9933e-01, 6.7382e-04],\n",
       "         [9.9999e-01, 9.0796e-06],\n",
       "         [9.2504e-01, 7.4957e-02]], grad_fn=<ClampBackward1>), tensor([[8.9779e-01, 1.0221e-01],\n",
       "         [9.7244e-01, 2.7563e-02],\n",
       "         [9.9999e-01, 1.3619e-05],\n",
       "         [8.8841e-01, 1.1159e-01]], grad_fn=<ClampBackward1>), tensor([[8.3030e-01, 1.6970e-01],\n",
       "         [9.2314e-01, 7.6864e-02],\n",
       "         [9.9998e-01, 1.8159e-05],\n",
       "         [8.5236e-01, 1.4764e-01]], grad_fn=<ClampBackward1>), tensor([[0.7667, 0.2333],\n",
       "         [0.8308, 0.1692],\n",
       "         [0.9500, 0.0500],\n",
       "         [0.8169, 0.1831]], grad_fn=<ClampBackward1>)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6873e-02, 1.6751e-02, 2.0997e-02, 1.5773e-02, 1.4882e-02],\n",
       "        [3.9518e-06, 5.7873e-04, 1.7234e-02, 2.1876e-02, 3.8703e-06],\n",
       "        [4.4261e-06, 4.4261e-06, 4.4261e-06, 4.4261e-06, 2.5000e-02],\n",
       "        [2.2024e-02, 2.1710e-02, 2.1386e-02, 2.1050e-02, 2.0704e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0767]])\n",
      "tensor([[0.2569]])\n"
     ]
    }
   ],
   "source": [
    "print(fuzzy_fsa.transitions[0].condition.linear.weight.grad)\n",
    "print(fuzzy_fsa.transitions[0].condition.linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последовательность с переключением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchingRegressor(torch.nn.Module):\n",
    "    def __init__(self, logic, ffsa):\n",
    "        super().__init__()\n",
    "        self.logic = logic\n",
    "        self.ffsa = ffsa\n",
    "        self.debug = False\n",
    "        \n",
    "    def forward(self, input, init_activation):\n",
    "        steps = input.size()[1]\n",
    "        \n",
    "        activations = [init_activation]\n",
    "        outputs = []\n",
    "        for step in range(steps):\n",
    "            # Срез входа по текущему шагу.\n",
    "            input_on_current_step = input[:, step]\n",
    "            \n",
    "            # Новые активации (согласно нечеткому конечному автомату).\n",
    "            activations.append(self.ffsa(input_on_current_step, activations[-1], 0.05))\n",
    "            \n",
    "            # Получение выходов регрессоров.\n",
    "            output = [state(input_on_current_step) for state in self.ffsa.states]\n",
    "            output = torch.stack(output, dim=1)\n",
    "            outputs.append(torch.einsum(\"bo,bo...->b...\", activations[-1], output))\n",
    "            \n",
    "        return torch.stack(outputs, dim=1), torch.stack(activations, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Логика.\n",
    "#Logic = logic.Godel\n",
    "#Logic = logic.Product\n",
    "#Logic = logic.Lukasiewicz\n",
    "#Logic = logic.Nilpotent\n",
    "Logic = logic.Hamacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = SwitchingRegressor(Logic, ffsa.TimeDependentFFSA(Logic, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.ffsa.states = torch.nn.ModuleList([torch.nn.Linear(2, 1), torch.nn.Linear(2, 1), torch.nn.Linear(2, 1)])\n",
    "regressor.ffsa.transitions = torch.nn.ModuleList([ffsa.FuzzyTransitionContinuous(0, 1, indicators.Sigmoid(2)),\n",
    "                                                  ffsa.FuzzyTransitionContinuous(0, 2, indicators.Sigmoid(2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Набор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "class SwitchingSequences(torch.utils.data.Dataset):\n",
    "    def __init__(self, length=100, delta=3):       \n",
    "        self.length = length\n",
    "        self.delta = delta\n",
    "        self.noize = stats.norm()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 16384\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        switch_index_start = np.random.choice(np.arange(0, self.length - self.delta - 1), 1)[0]\n",
    "        switch_index_end = np.random.choice(np.arange(switch_index_start + self.delta, self.length), 1)[0]\n",
    "        switch_type = np.random.choice([-1.0, 1.0], 1)[0]\n",
    "        \n",
    "        X = np.ones((self.length, 2))\n",
    "        X[:,1] *= switch_type\n",
    "        X[:switch_index_start, 1] = 0.0\n",
    "        X[switch_index_end:, 1] = 0.0\n",
    "        X += self.noize.rvs(X.shape) * 0.1\n",
    "        \n",
    "        y = np.ones((self.length))\n",
    "        y[switch_index_start:] = 4.0 * switch_type * X[switch_index_start:, 0]\n",
    "        y += self.noize.rvs(y.shape) * 0.1\n",
    "        \n",
    "        return X.astype(np.float32), y.astype(np.float32)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SwitchingSequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(regressor.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.377\n",
      "[1,     2] loss: 1.814\n",
      "[1,     3] loss: 1.427\n",
      "[1,     4] loss: 1.365\n",
      "[1,     5] loss: 1.093\n",
      "[1,     6] loss: 0.903\n",
      "[1,     7] loss: 0.780\n",
      "[1,     8] loss: 0.623\n",
      "[1,     9] loss: 0.564\n",
      "[1,    10] loss: 0.557\n",
      "[1,    11] loss: 0.602\n",
      "[1,    12] loss: 0.569\n",
      "[1,    13] loss: 0.517\n",
      "[1,    14] loss: 0.582\n",
      "[1,    15] loss: 0.598\n",
      "[1,    16] loss: 0.593\n",
      "[1,    17] loss: 0.605\n",
      "[1,    18] loss: 0.655\n",
      "[1,    19] loss: 0.517\n",
      "[1,    20] loss: 0.549\n",
      "[1,    21] loss: 0.545\n",
      "[1,    22] loss: 0.528\n",
      "[1,    23] loss: 0.464\n",
      "[1,    24] loss: 0.459\n",
      "[1,    25] loss: 0.357\n",
      "[1,    26] loss: 0.394\n",
      "[1,    27] loss: 0.388\n",
      "[1,    28] loss: 0.363\n",
      "[1,    29] loss: 0.391\n",
      "[1,    30] loss: 0.381\n",
      "[1,    31] loss: 0.347\n",
      "[1,    32] loss: 0.397\n",
      "[2,     1] loss: 0.384\n",
      "[2,     2] loss: 0.364\n",
      "[2,     3] loss: 0.355\n",
      "[2,     4] loss: 0.369\n",
      "[2,     5] loss: 0.348\n",
      "[2,     6] loss: 0.350\n",
      "[2,     7] loss: 0.351\n",
      "[2,     8] loss: 0.312\n",
      "[2,     9] loss: 0.313\n",
      "[2,    10] loss: 0.323\n",
      "[2,    11] loss: 0.285\n",
      "[2,    12] loss: 0.279\n",
      "[2,    13] loss: 0.307\n",
      "[2,    14] loss: 0.289\n",
      "[2,    15] loss: 0.315\n",
      "[2,    16] loss: 0.310\n",
      "[2,    17] loss: 0.302\n",
      "[2,    18] loss: 0.282\n",
      "[2,    19] loss: 0.314\n",
      "[2,    20] loss: 0.284\n",
      "[2,    21] loss: 0.292\n",
      "[2,    22] loss: 0.293\n",
      "[2,    23] loss: 0.277\n",
      "[2,    24] loss: 0.296\n",
      "[2,    25] loss: 0.250\n",
      "[2,    26] loss: 0.273\n",
      "[2,    27] loss: 0.277\n",
      "[2,    28] loss: 0.273\n",
      "[2,    29] loss: 0.267\n",
      "[2,    30] loss: 0.243\n",
      "[2,    31] loss: 0.261\n",
      "[2,    32] loss: 0.285\n",
      "[3,     1] loss: 0.262\n",
      "[3,     2] loss: 0.275\n",
      "[3,     3] loss: 0.244\n",
      "[3,     4] loss: 0.271\n",
      "[3,     5] loss: 0.289\n",
      "[3,     6] loss: 0.251\n",
      "[3,     7] loss: 0.231\n",
      "[3,     8] loss: 0.251\n",
      "[3,     9] loss: 0.245\n",
      "[3,    10] loss: 0.219\n",
      "[3,    11] loss: 0.231\n",
      "[3,    12] loss: 0.238\n",
      "[3,    13] loss: 0.230\n",
      "[3,    14] loss: 0.212\n",
      "[3,    15] loss: 0.216\n",
      "[3,    16] loss: 0.216\n",
      "[3,    17] loss: 0.238\n",
      "[3,    18] loss: 0.226\n",
      "[3,    19] loss: 0.222\n",
      "[3,    20] loss: 0.214\n",
      "[3,    21] loss: 0.201\n",
      "[3,    22] loss: 0.197\n",
      "[3,    23] loss: 0.202\n",
      "[3,    24] loss: 0.198\n",
      "[3,    25] loss: 0.210\n",
      "[3,    26] loss: 0.209\n",
      "[3,    27] loss: 0.176\n",
      "[3,    28] loss: 0.225\n",
      "[3,    29] loss: 0.189\n",
      "[3,    30] loss: 0.227\n",
      "[3,    31] loss: 0.200\n",
      "[3,    32] loss: 0.186\n",
      "[4,     1] loss: 0.162\n",
      "[4,     2] loss: 0.167\n",
      "[4,     3] loss: 0.168\n",
      "[4,     4] loss: 0.154\n",
      "[4,     5] loss: 0.177\n",
      "[4,     6] loss: 0.168\n",
      "[4,     7] loss: 0.173\n",
      "[4,     8] loss: 0.159\n",
      "[4,     9] loss: 0.162\n",
      "[4,    10] loss: 0.151\n",
      "[4,    11] loss: 0.157\n",
      "[4,    12] loss: 0.170\n",
      "[4,    13] loss: 0.168\n",
      "[4,    14] loss: 0.185\n",
      "[4,    15] loss: 0.143\n",
      "[4,    16] loss: 0.151\n",
      "[4,    17] loss: 0.148\n",
      "[4,    18] loss: 0.132\n",
      "[4,    19] loss: 0.164\n",
      "[4,    20] loss: 0.164\n",
      "[4,    21] loss: 0.154\n",
      "[4,    22] loss: 0.140\n",
      "[4,    23] loss: 0.131\n",
      "[4,    24] loss: 0.134\n",
      "[4,    25] loss: 0.137\n",
      "[4,    26] loss: 0.146\n",
      "[4,    27] loss: 0.134\n",
      "[4,    28] loss: 0.135\n",
      "[4,    29] loss: 0.138\n",
      "[4,    30] loss: 0.155\n",
      "[4,    31] loss: 0.129\n",
      "[4,    32] loss: 0.133\n",
      "[5,     1] loss: 0.133\n",
      "[5,     2] loss: 0.138\n",
      "[5,     3] loss: 0.125\n",
      "[5,     4] loss: 0.134\n",
      "[5,     5] loss: 0.135\n",
      "[5,     6] loss: 0.152\n",
      "[5,     7] loss: 0.128\n",
      "[5,     8] loss: 0.134\n",
      "[5,     9] loss: 0.115\n",
      "[5,    10] loss: 0.130\n",
      "[5,    11] loss: 0.145\n",
      "[5,    12] loss: 0.106\n",
      "[5,    13] loss: 0.151\n",
      "[5,    14] loss: 0.117\n",
      "[5,    15] loss: 0.124\n",
      "[5,    16] loss: 0.139\n",
      "[5,    17] loss: 0.120\n",
      "[5,    18] loss: 0.123\n",
      "[5,    19] loss: 0.116\n",
      "[5,    20] loss: 0.119\n",
      "[5,    21] loss: 0.108\n",
      "[5,    22] loss: 0.132\n",
      "[5,    23] loss: 0.117\n",
      "[5,    24] loss: 0.103\n",
      "[5,    25] loss: 0.107\n",
      "[5,    26] loss: 0.103\n",
      "[5,    27] loss: 0.114\n",
      "[5,    28] loss: 0.115\n",
      "[5,    29] loss: 0.115\n",
      "[5,    30] loss: 0.107\n",
      "[5,    31] loss: 0.100\n",
      "[5,    32] loss: 0.110\n",
      "[6,     1] loss: 0.104\n",
      "[6,     2] loss: 0.116\n",
      "[6,     3] loss: 0.107\n",
      "[6,     4] loss: 0.110\n",
      "[6,     5] loss: 0.104\n",
      "[6,     6] loss: 0.092\n",
      "[6,     7] loss: 0.100\n",
      "[6,     8] loss: 0.117\n",
      "[6,     9] loss: 0.104\n",
      "[6,    10] loss: 0.094\n",
      "[6,    11] loss: 0.105\n",
      "[6,    12] loss: 0.097\n",
      "[6,    13] loss: 0.111\n",
      "[6,    14] loss: 0.096\n",
      "[6,    15] loss: 0.108\n",
      "[6,    16] loss: 0.098\n",
      "[6,    17] loss: 0.101\n",
      "[6,    18] loss: 0.099\n",
      "[6,    19] loss: 0.095\n",
      "[6,    20] loss: 0.114\n",
      "[6,    21] loss: 0.093\n",
      "[6,    22] loss: 0.095\n",
      "[6,    23] loss: 0.115\n",
      "[6,    24] loss: 0.086\n",
      "[6,    25] loss: 0.090\n",
      "[6,    26] loss: 0.113\n",
      "[6,    27] loss: 0.086\n",
      "[6,    28] loss: 0.089\n",
      "[6,    29] loss: 0.087\n",
      "[6,    30] loss: 0.087\n",
      "[6,    31] loss: 0.094\n",
      "[6,    32] loss: 0.102\n",
      "[7,     1] loss: 0.092\n",
      "[7,     2] loss: 0.103\n",
      "[7,     3] loss: 0.081\n",
      "[7,     4] loss: 0.105\n",
      "[7,     5] loss: 0.106\n",
      "[7,     6] loss: 0.095\n",
      "[7,     7] loss: 0.091\n",
      "[7,     8] loss: 0.094\n",
      "[7,     9] loss: 0.082\n",
      "[7,    10] loss: 0.085\n",
      "[7,    11] loss: 0.088\n",
      "[7,    12] loss: 0.091\n",
      "[7,    13] loss: 0.091\n",
      "[7,    14] loss: 0.096\n",
      "[7,    15] loss: 0.090\n",
      "[7,    16] loss: 0.087\n",
      "[7,    17] loss: 0.084\n",
      "[7,    18] loss: 0.085\n",
      "[7,    19] loss: 0.083\n",
      "[7,    20] loss: 0.084\n",
      "[7,    21] loss: 0.079\n",
      "[7,    22] loss: 0.083\n",
      "[7,    23] loss: 0.080\n",
      "[7,    24] loss: 0.084\n",
      "[7,    25] loss: 0.074\n",
      "[7,    26] loss: 0.093\n",
      "[7,    27] loss: 0.082\n",
      "[7,    28] loss: 0.077\n",
      "[7,    29] loss: 0.069\n",
      "[7,    30] loss: 0.084\n",
      "[7,    31] loss: 0.088\n",
      "[7,    32] loss: 0.084\n",
      "[8,     1] loss: 0.078\n",
      "[8,     2] loss: 0.070\n",
      "[8,     3] loss: 0.084\n",
      "[8,     4] loss: 0.076\n",
      "[8,     5] loss: 0.077\n",
      "[8,     6] loss: 0.087\n",
      "[8,     7] loss: 0.081\n",
      "[8,     8] loss: 0.085\n",
      "[8,     9] loss: 0.076\n",
      "[8,    10] loss: 0.083\n",
      "[8,    11] loss: 0.078\n",
      "[8,    12] loss: 0.077\n",
      "[8,    13] loss: 0.077\n",
      "[8,    14] loss: 0.080\n",
      "[8,    15] loss: 0.076\n",
      "[8,    16] loss: 0.073\n",
      "[8,    17] loss: 0.086\n",
      "[8,    18] loss: 0.086\n",
      "[8,    19] loss: 0.070\n",
      "[8,    20] loss: 0.079\n",
      "[8,    21] loss: 0.072\n",
      "[8,    22] loss: 0.085\n",
      "[8,    23] loss: 0.078\n",
      "[8,    24] loss: 0.075\n",
      "[8,    25] loss: 0.077\n",
      "[8,    26] loss: 0.080\n",
      "[8,    27] loss: 0.079\n",
      "[8,    28] loss: 0.078\n",
      "[8,    29] loss: 0.071\n",
      "[8,    30] loss: 0.071\n",
      "[8,    31] loss: 0.084\n",
      "[8,    32] loss: 0.074\n",
      "[9,     1] loss: 0.067\n",
      "[9,     2] loss: 0.080\n",
      "[9,     3] loss: 0.077\n",
      "[9,     4] loss: 0.085\n",
      "[9,     5] loss: 0.075\n",
      "[9,     6] loss: 0.074\n",
      "[9,     7] loss: 0.072\n",
      "[9,     8] loss: 0.073\n",
      "[9,     9] loss: 0.066\n",
      "[9,    10] loss: 0.063\n",
      "[9,    11] loss: 0.067\n",
      "[9,    12] loss: 0.076\n",
      "[9,    13] loss: 0.071\n",
      "[9,    14] loss: 0.057\n",
      "[9,    15] loss: 0.072\n",
      "[9,    16] loss: 0.066\n",
      "[9,    17] loss: 0.062\n",
      "[9,    18] loss: 0.067\n",
      "[9,    19] loss: 0.071\n",
      "[9,    20] loss: 0.070\n",
      "[9,    21] loss: 0.067\n",
      "[9,    22] loss: 0.065\n",
      "[9,    23] loss: 0.062\n",
      "[9,    24] loss: 0.064\n",
      "[9,    25] loss: 0.072\n",
      "[9,    26] loss: 0.076\n",
      "[9,    27] loss: 0.064\n",
      "[9,    28] loss: 0.075\n",
      "[9,    29] loss: 0.057\n",
      "[9,    30] loss: 0.063\n",
      "[9,    31] loss: 0.066\n",
      "[9,    32] loss: 0.064\n",
      "[10,     1] loss: 0.073\n",
      "[10,     2] loss: 0.067\n",
      "[10,     3] loss: 0.070\n",
      "[10,     4] loss: 0.065\n",
      "[10,     5] loss: 0.063\n",
      "[10,     6] loss: 0.069\n",
      "[10,     7] loss: 0.067\n",
      "[10,     8] loss: 0.059\n",
      "[10,     9] loss: 0.061\n",
      "[10,    10] loss: 0.060\n",
      "[10,    11] loss: 0.057\n",
      "[10,    12] loss: 0.062\n",
      "[10,    13] loss: 0.060\n",
      "[10,    14] loss: 0.059\n",
      "[10,    15] loss: 0.062\n",
      "[10,    16] loss: 0.059\n",
      "[10,    17] loss: 0.062\n",
      "[10,    18] loss: 0.064\n",
      "[10,    19] loss: 0.060\n",
      "[10,    20] loss: 0.063\n",
      "[10,    21] loss: 0.060\n",
      "[10,    22] loss: 0.063\n",
      "[10,    23] loss: 0.061\n",
      "[10,    24] loss: 0.068\n",
      "[10,    25] loss: 0.061\n",
      "[10,    26] loss: 0.059\n",
      "[10,    27] loss: 0.062\n",
      "[10,    28] loss: 0.057\n",
      "[10,    29] loss: 0.078\n",
      "[10,    30] loss: 0.062\n",
      "[10,    31] loss: 0.054\n",
      "[10,    32] loss: 0.059\n",
      "[11,     1] loss: 0.062\n",
      "[11,     2] loss: 0.060\n",
      "[11,     3] loss: 0.058\n",
      "[11,     4] loss: 0.060\n",
      "[11,     5] loss: 0.061\n",
      "[11,     6] loss: 0.059\n",
      "[11,     7] loss: 0.062\n",
      "[11,     8] loss: 0.058\n",
      "[11,     9] loss: 0.057\n",
      "[11,    10] loss: 0.062\n",
      "[11,    11] loss: 0.053\n",
      "[11,    12] loss: 0.060\n",
      "[11,    13] loss: 0.052\n",
      "[11,    14] loss: 0.059\n",
      "[11,    15] loss: 0.059\n",
      "[11,    16] loss: 0.065\n",
      "[11,    17] loss: 0.065\n",
      "[11,    18] loss: 0.055\n",
      "[11,    19] loss: 0.050\n",
      "[11,    20] loss: 0.066\n",
      "[11,    21] loss: 0.058\n",
      "[11,    22] loss: 0.061\n",
      "[11,    23] loss: 0.057\n",
      "[11,    24] loss: 0.064\n",
      "[11,    25] loss: 0.062\n",
      "[11,    26] loss: 0.053\n",
      "[11,    27] loss: 0.053\n",
      "[11,    28] loss: 0.061\n",
      "[11,    29] loss: 0.056\n",
      "[11,    30] loss: 0.057\n",
      "[11,    31] loss: 0.054\n",
      "[11,    32] loss: 0.050\n",
      "[12,     1] loss: 0.053\n",
      "[12,     2] loss: 0.051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,     3] loss: 0.054\n",
      "[12,     4] loss: 0.060\n",
      "[12,     5] loss: 0.056\n",
      "[12,     6] loss: 0.050\n",
      "[12,     7] loss: 0.057\n",
      "[12,     8] loss: 0.054\n",
      "[12,     9] loss: 0.049\n",
      "[12,    10] loss: 0.051\n",
      "[12,    11] loss: 0.057\n",
      "[12,    12] loss: 0.053\n",
      "[12,    13] loss: 0.050\n",
      "[12,    14] loss: 0.055\n",
      "[12,    15] loss: 0.058\n",
      "[12,    16] loss: 0.053\n",
      "[12,    17] loss: 0.049\n",
      "[12,    18] loss: 0.055\n",
      "[12,    19] loss: 0.056\n",
      "[12,    20] loss: 0.053\n",
      "[12,    21] loss: 0.049\n",
      "[12,    22] loss: 0.053\n",
      "[12,    23] loss: 0.066\n",
      "[12,    24] loss: 0.059\n",
      "[12,    25] loss: 0.058\n",
      "[12,    26] loss: 0.057\n",
      "[12,    27] loss: 0.055\n",
      "[12,    28] loss: 0.054\n",
      "[12,    29] loss: 0.055\n",
      "[12,    30] loss: 0.059\n",
      "[12,    31] loss: 0.051\n",
      "[12,    32] loss: 0.054\n",
      "[13,     1] loss: 0.052\n",
      "[13,     2] loss: 0.054\n",
      "[13,     3] loss: 0.049\n",
      "[13,     4] loss: 0.050\n",
      "[13,     5] loss: 0.051\n",
      "[13,     6] loss: 0.048\n",
      "[13,     7] loss: 0.055\n",
      "[13,     8] loss: 0.051\n",
      "[13,     9] loss: 0.048\n",
      "[13,    10] loss: 0.048\n",
      "[13,    11] loss: 0.052\n",
      "[13,    12] loss: 0.054\n",
      "[13,    13] loss: 0.050\n",
      "[13,    14] loss: 0.049\n",
      "[13,    15] loss: 0.051\n",
      "[13,    16] loss: 0.049\n",
      "[13,    17] loss: 0.053\n",
      "[13,    18] loss: 0.052\n",
      "[13,    19] loss: 0.050\n",
      "[13,    20] loss: 0.048\n",
      "[13,    21] loss: 0.050\n",
      "[13,    22] loss: 0.050\n",
      "[13,    23] loss: 0.049\n",
      "[13,    24] loss: 0.047\n",
      "[13,    25] loss: 0.047\n",
      "[13,    26] loss: 0.046\n",
      "[13,    27] loss: 0.055\n",
      "[13,    28] loss: 0.048\n",
      "[13,    29] loss: 0.049\n",
      "[13,    30] loss: 0.050\n",
      "[13,    31] loss: 0.055\n",
      "[13,    32] loss: 0.050\n",
      "[14,     1] loss: 0.049\n",
      "[14,     2] loss: 0.054\n",
      "[14,     3] loss: 0.052\n",
      "[14,     4] loss: 0.046\n",
      "[14,     5] loss: 0.049\n",
      "[14,     6] loss: 0.054\n",
      "[14,     7] loss: 0.049\n",
      "[14,     8] loss: 0.048\n",
      "[14,     9] loss: 0.048\n",
      "[14,    10] loss: 0.055\n",
      "[14,    11] loss: 0.055\n",
      "[14,    12] loss: 0.047\n",
      "[14,    13] loss: 0.048\n",
      "[14,    14] loss: 0.046\n",
      "[14,    15] loss: 0.054\n",
      "[14,    16] loss: 0.054\n",
      "[14,    17] loss: 0.049\n",
      "[14,    18] loss: 0.052\n",
      "[14,    19] loss: 0.050\n",
      "[14,    20] loss: 0.045\n",
      "[14,    21] loss: 0.050\n",
      "[14,    22] loss: 0.048\n",
      "[14,    23] loss: 0.049\n",
      "[14,    24] loss: 0.049\n",
      "[14,    25] loss: 0.049\n",
      "[14,    26] loss: 0.043\n",
      "[14,    27] loss: 0.042\n",
      "[14,    28] loss: 0.047\n",
      "[14,    29] loss: 0.041\n",
      "[14,    30] loss: 0.044\n",
      "[14,    31] loss: 0.050\n",
      "[14,    32] loss: 0.049\n",
      "[15,     1] loss: 0.048\n",
      "[15,     2] loss: 0.051\n",
      "[15,     3] loss: 0.055\n",
      "[15,     4] loss: 0.048\n",
      "[15,     5] loss: 0.048\n",
      "[15,     6] loss: 0.046\n",
      "[15,     7] loss: 0.055\n",
      "[15,     8] loss: 0.045\n",
      "[15,     9] loss: 0.046\n",
      "[15,    10] loss: 0.046\n",
      "[15,    11] loss: 0.049\n",
      "[15,    12] loss: 0.044\n",
      "[15,    13] loss: 0.048\n",
      "[15,    14] loss: 0.042\n",
      "[15,    15] loss: 0.046\n",
      "[15,    16] loss: 0.048\n",
      "[15,    17] loss: 0.044\n",
      "[15,    18] loss: 0.048\n",
      "[15,    19] loss: 0.049\n",
      "[15,    20] loss: 0.049\n",
      "[15,    21] loss: 0.047\n",
      "[15,    22] loss: 0.042\n",
      "[15,    23] loss: 0.047\n",
      "[15,    24] loss: 0.044\n",
      "[15,    25] loss: 0.051\n",
      "[15,    26] loss: 0.044\n",
      "[15,    27] loss: 0.048\n",
      "[15,    28] loss: 0.045\n",
      "[15,    29] loss: 0.043\n",
      "[15,    30] loss: 0.043\n",
      "[15,    31] loss: 0.048\n",
      "[15,    32] loss: 0.043\n",
      "[16,     1] loss: 0.048\n",
      "[16,     2] loss: 0.043\n",
      "[16,     3] loss: 0.047\n",
      "[16,     4] loss: 0.045\n",
      "[16,     5] loss: 0.046\n",
      "[16,     6] loss: 0.042\n",
      "[16,     7] loss: 0.042\n",
      "[16,     8] loss: 0.040\n",
      "[16,     9] loss: 0.041\n",
      "[16,    10] loss: 0.047\n",
      "[16,    11] loss: 0.043\n",
      "[16,    12] loss: 0.046\n",
      "[16,    13] loss: 0.043\n",
      "[16,    14] loss: 0.043\n",
      "[16,    15] loss: 0.043\n",
      "[16,    16] loss: 0.039\n",
      "[16,    17] loss: 0.042\n",
      "[16,    18] loss: 0.045\n",
      "[16,    19] loss: 0.044\n",
      "[16,    20] loss: 0.042\n",
      "[16,    21] loss: 0.042\n",
      "[16,    22] loss: 0.043\n",
      "[16,    23] loss: 0.046\n",
      "[16,    24] loss: 0.039\n",
      "[16,    25] loss: 0.044\n",
      "[16,    26] loss: 0.045\n",
      "[16,    27] loss: 0.048\n",
      "[16,    28] loss: 0.040\n",
      "[16,    29] loss: 0.044\n",
      "[16,    30] loss: 0.041\n",
      "[16,    31] loss: 0.043\n",
      "[16,    32] loss: 0.042\n",
      "[17,     1] loss: 0.043\n",
      "[17,     2] loss: 0.045\n",
      "[17,     3] loss: 0.042\n",
      "[17,     4] loss: 0.042\n",
      "[17,     5] loss: 0.043\n",
      "[17,     6] loss: 0.043\n",
      "[17,     7] loss: 0.046\n",
      "[17,     8] loss: 0.041\n",
      "[17,     9] loss: 0.048\n",
      "[17,    10] loss: 0.042\n",
      "[17,    11] loss: 0.042\n",
      "[17,    12] loss: 0.041\n",
      "[17,    13] loss: 0.040\n",
      "[17,    14] loss: 0.050\n",
      "[17,    15] loss: 0.039\n",
      "[17,    16] loss: 0.042\n",
      "[17,    17] loss: 0.041\n",
      "[17,    18] loss: 0.045\n",
      "[17,    19] loss: 0.039\n",
      "[17,    20] loss: 0.043\n",
      "[17,    21] loss: 0.043\n",
      "[17,    22] loss: 0.042\n",
      "[17,    23] loss: 0.040\n",
      "[17,    24] loss: 0.043\n",
      "[17,    25] loss: 0.050\n",
      "[17,    26] loss: 0.038\n",
      "[17,    27] loss: 0.042\n",
      "[17,    28] loss: 0.043\n",
      "[17,    29] loss: 0.040\n",
      "[17,    30] loss: 0.042\n",
      "[17,    31] loss: 0.040\n",
      "[17,    32] loss: 0.039\n",
      "[18,     1] loss: 0.040\n",
      "[18,     2] loss: 0.042\n",
      "[18,     3] loss: 0.038\n",
      "[18,     4] loss: 0.042\n",
      "[18,     5] loss: 0.042\n",
      "[18,     6] loss: 0.039\n",
      "[18,     7] loss: 0.042\n",
      "[18,     8] loss: 0.040\n",
      "[18,     9] loss: 0.038\n",
      "[18,    10] loss: 0.042\n",
      "[18,    11] loss: 0.042\n",
      "[18,    12] loss: 0.039\n",
      "[18,    13] loss: 0.041\n",
      "[18,    14] loss: 0.037\n",
      "[18,    15] loss: 0.038\n",
      "[18,    16] loss: 0.037\n",
      "[18,    17] loss: 0.037\n",
      "[18,    18] loss: 0.041\n",
      "[18,    19] loss: 0.038\n",
      "[18,    20] loss: 0.038\n",
      "[18,    21] loss: 0.040\n",
      "[18,    22] loss: 0.039\n",
      "[18,    23] loss: 0.037\n",
      "[18,    24] loss: 0.041\n",
      "[18,    25] loss: 0.036\n",
      "[18,    26] loss: 0.039\n",
      "[18,    27] loss: 0.042\n",
      "[18,    28] loss: 0.040\n",
      "[18,    29] loss: 0.037\n",
      "[18,    30] loss: 0.040\n",
      "[18,    31] loss: 0.039\n",
      "[18,    32] loss: 0.040\n",
      "[19,     1] loss: 0.038\n",
      "[19,     2] loss: 0.041\n",
      "[19,     3] loss: 0.037\n",
      "[19,     4] loss: 0.038\n",
      "[19,     5] loss: 0.037\n",
      "[19,     6] loss: 0.041\n",
      "[19,     7] loss: 0.042\n",
      "[19,     8] loss: 0.041\n",
      "[19,     9] loss: 0.038\n",
      "[19,    10] loss: 0.042\n",
      "[19,    11] loss: 0.038\n",
      "[19,    12] loss: 0.039\n",
      "[19,    13] loss: 0.036\n",
      "[19,    14] loss: 0.040\n",
      "[19,    15] loss: 0.036\n",
      "[19,    16] loss: 0.039\n",
      "[19,    17] loss: 0.042\n",
      "[19,    18] loss: 0.036\n",
      "[19,    19] loss: 0.035\n",
      "[19,    20] loss: 0.037\n",
      "[19,    21] loss: 0.036\n",
      "[19,    22] loss: 0.038\n",
      "[19,    23] loss: 0.042\n",
      "[19,    24] loss: 0.035\n",
      "[19,    25] loss: 0.037\n",
      "[19,    26] loss: 0.036\n",
      "[19,    27] loss: 0.038\n",
      "[19,    28] loss: 0.039\n",
      "[19,    29] loss: 0.042\n",
      "[19,    30] loss: 0.037\n",
      "[19,    31] loss: 0.038\n",
      "[19,    32] loss: 0.037\n",
      "[20,     1] loss: 0.038\n",
      "[20,     2] loss: 0.039\n",
      "[20,     3] loss: 0.036\n",
      "[20,     4] loss: 0.038\n",
      "[20,     5] loss: 0.037\n",
      "[20,     6] loss: 0.039\n",
      "[20,     7] loss: 0.037\n",
      "[20,     8] loss: 0.039\n",
      "[20,     9] loss: 0.037\n",
      "[20,    10] loss: 0.035\n",
      "[20,    11] loss: 0.039\n",
      "[20,    12] loss: 0.037\n",
      "[20,    13] loss: 0.037\n",
      "[20,    14] loss: 0.039\n",
      "[20,    15] loss: 0.041\n",
      "[20,    16] loss: 0.037\n",
      "[20,    17] loss: 0.038\n",
      "[20,    18] loss: 0.036\n",
      "[20,    19] loss: 0.040\n",
      "[20,    20] loss: 0.036\n",
      "[20,    21] loss: 0.037\n",
      "[20,    22] loss: 0.036\n",
      "[20,    23] loss: 0.036\n",
      "[20,    24] loss: 0.037\n",
      "[20,    25] loss: 0.036\n",
      "[20,    26] loss: 0.041\n",
      "[20,    27] loss: 0.036\n",
      "[20,    28] loss: 0.037\n",
      "[20,    29] loss: 0.036\n",
      "[20,    30] loss: 0.036\n",
      "[20,    31] loss: 0.035\n",
      "[20,    32] loss: 0.036\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        x, true_y = data\n",
    "        init_activations = torch.zeros(x.size()[0], 3)\n",
    "        init_activations[:,0] = 1.0\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        y, activations = regressor(x, init_activations)\n",
    "        eval_loss = loss(y, true_y)\n",
    "        eval_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += eval_loss.item()\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.0636816   1.1271845   0.96690947  0.9399483   0.89591223  1.0893327\n",
      "  0.9902807   1.1074219   0.8486005   0.99929607  0.9036388   0.9770301\n",
      "  0.9922872   1.0501469   0.8978201   0.88019955  1.0069315   0.8284542\n",
      "  1.2606331   1.0277216   1.0025424   0.9353081   1.0308428   0.9126508\n",
      "  0.8804698   0.9993591   0.9339324   1.1085291   1.0614871   1.0736322\n",
      "  0.8583249   1.2489167   0.7749296   1.0065045   1.21576    -4.212572\n",
      " -4.2949495  -4.099417   -4.081355   -4.1245756  -3.1380196  -3.8981912\n",
      " -4.034328   -3.8807492  -4.2461705  -3.7869663  -4.31014    -4.0272746\n",
      " -4.23155    -3.8829606  -2.9306242  -3.720491   -4.8416324  -4.0280437\n",
      " -4.571766   -3.6654613  -4.6328936  -4.0595636  -5.0068264  -3.7584162\n",
      " -3.5817647  -4.0784016  -3.202081   -3.4220936  -3.0548804  -4.4677525\n",
      " -3.8817286  -3.9379535  -4.1695156  -3.9721007  -4.1572433  -4.9272237\n",
      " -4.573931   -3.8898299  -3.8300617  -3.5908124  -3.6964996  -4.5851994\n",
      " -4.240703   -3.6830387  -4.0223193  -4.134002   -4.0102105  -3.5361845\n",
      " -4.573006   -3.7853634  -3.3094757  -4.2675548  -3.9977388  -3.8520443\n",
      " -3.9310918  -4.155614   -4.1870008  -4.192239   -4.599363   -3.8545427\n",
      " -4.1663184  -3.7116184  -4.3505244  -3.8573031 ]\n",
      "[ 0.9219141   1.0864364   1.0383826   1.0656061   0.6886408   0.91447085\n",
      "  0.8685791   1.0896429   1.0435767   0.9806229   1.1113119   0.7831601\n",
      "  0.8110304   0.9070412   1.1233685   0.9594405   1.0091937   0.99651957\n",
      "  1.049083    1.084635    1.0613698   1.1846958   0.9401267   1.1861323\n",
      "  0.97058475  1.2299991   1.127367    1.261822    1.0072393   0.99976146\n",
      "  1.2348115   1.1756067   0.990406    0.95675933  1.0169321  -4.1700926\n",
      " -4.25814    -4.152774   -4.262236   -4.1225376  -3.2065952  -3.8199406\n",
      " -3.9856489  -3.888954   -4.32895    -3.8710394  -4.290031   -4.083595\n",
      " -4.18346    -3.8979225  -2.9240615  -3.7379627  -4.764855   -4.023154\n",
      " -4.4787045  -3.6371932  -4.656295   -4.051273   -4.899426   -3.7416084\n",
      " -3.5219116  -4.1408467  -3.2122493  -3.5161252  -3.3081946  -4.442811\n",
      " -3.994737   -4.0699816  -4.216519   -4.149263   -4.253392   -4.8987465\n",
      " -4.6386027  -4.0445023  -3.7713227  -3.7176783  -3.5990334  -4.5442696\n",
      " -4.1290092  -3.672859   -3.9810357  -4.090888   -3.980187   -3.567484\n",
      " -4.5259657  -3.7618825  -3.444252   -4.334871   -3.985594   -3.8023534\n",
      " -3.8910203  -3.9750972  -4.3118258  -4.1698384  -4.644825   -4.0105453\n",
      " -4.0842     -3.6984243  -4.276421   -3.9232244 ]\n"
     ]
    }
   ],
   "source": [
    "X, y_true = dataset[0]\n",
    "X = torch.tensor(X)[None,:]\n",
    "y, activations = regressor(X, torch.tensor(np.array([[1.0, 0.0, 0.0]]).astype(np.float32)))\n",
    "\n",
    "print(y_true.squeeze())\n",
    "print(y.squeeze().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1417675 ,  0.04074812, -0.07147318, -0.1256578 ,  0.20727146,\n",
       "        0.17486185,  0.1217016 ,  0.01777899, -0.19497621,  0.01867318,\n",
       "       -0.20767313,  0.19387001,  0.18125683,  0.14310575, -0.22554839,\n",
       "       -0.07924098, -0.00226212, -0.16806537,  0.21155012, -0.05691338,\n",
       "       -0.0588274 , -0.24938774,  0.09071606, -0.2734815 , -0.09011495,\n",
       "       -0.23064   , -0.1934346 , -0.1532929 ,  0.05424774,  0.07387078,\n",
       "       -0.37648666,  0.07331002, -0.2154764 ,  0.0497452 ,  0.19882786,\n",
       "       -0.04247952, -0.03680944,  0.05335665,  0.18088102, -0.002038  ,\n",
       "        0.06857562, -0.07825065, -0.04867911,  0.0082047 ,  0.08277941,\n",
       "        0.08407307, -0.02010918,  0.05632019, -0.04808998,  0.01496196,\n",
       "       -0.00656271,  0.01747179, -0.07677746, -0.00488997, -0.09306145,\n",
       "       -0.0282681 ,  0.02340126, -0.00829077, -0.10740042, -0.01680779,\n",
       "       -0.05985308,  0.06244516,  0.01016831,  0.09403157,  0.25331426,\n",
       "       -0.02494144,  0.11300826,  0.1320281 ,  0.04700327,  0.17716217,\n",
       "        0.09614897, -0.02847719,  0.06467152,  0.15467238, -0.05873895,\n",
       "        0.12686586, -0.09746623, -0.04092979, -0.11169386, -0.01017976,\n",
       "       -0.04128361, -0.04311419, -0.03002357,  0.03129935, -0.04704046,\n",
       "       -0.02348089,  0.13477635,  0.06731606, -0.0121448 , -0.04969096,\n",
       "       -0.04007149, -0.18051672,  0.124825  , -0.02240038,  0.04546213,\n",
       "        0.15600252, -0.08211851, -0.01319408, -0.07410336,  0.06592131],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.squeeze() - y.squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations.argmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations.sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первое условие (параметры):\n",
      "[6.8892913]\n",
      "[[-4.028718 11.741827]]\n",
      "[-3.8700418]\n",
      "Второе условие (параметры):\n",
      "[21.689459]\n",
      "[[ -6.4538674 -21.918095 ]]\n",
      "[-8.063359]\n"
     ]
    }
   ],
   "source": [
    "print(\"Первое условие (параметры):\")\n",
    "print(regressor.ffsa.transitions[0].speed.detach().numpy())\n",
    "print(regressor.ffsa.transitions[0].condition.linear.weight.detach().numpy())\n",
    "print(regressor.ffsa.transitions[0].condition.linear.bias.detach().numpy())\n",
    "\n",
    "print(\"Второе условие (параметры):\")\n",
    "print(regressor.ffsa.transitions[1].speed.detach().numpy())\n",
    "print(regressor.ffsa.transitions[1].condition.linear.weight.detach().numpy())\n",
    "print(regressor.ffsa.transitions[1].condition.linear.bias.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
